{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1062ad1f",
   "metadata": {},
   "source": [
    "# Zero-Shot Learning for Record Linkage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35be7dbb",
   "metadata": {},
   "source": [
    "## Load database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0846e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f602894d",
   "metadata": {},
   "source": [
    "## Instantiate collection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2fb0789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import transformers  # old version '4.25.1'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForZeroShotImageClassification\n",
    "from tools.weaving_tools import SMGCollection,NMSCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5b5b102",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = NMSCollection(img_folder=Path('nms_imgs'))\n",
    "collection.load_from_csv('data/NMS.csv')\n",
    "collection.filter_records()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a58ed81",
   "metadata": {},
   "source": [
    "# Mapping Images to Taxonomies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ca518e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint = 'openai/clip-vit-base-patch32'\n",
    "model = AutoModelForZeroShotImageClassification.from_pretrained(checkpoint)\n",
    "processor = AutoProcessor.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e752b566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OFFICE EQUIPMENT',\n",
       " 'CIVIL ENGINEERING',\n",
       " 'PHOTOGRAPHY',\n",
       " 'DOMESTIC',\n",
       " 'MINERAL OILS',\n",
       " 'TRANSPORT',\n",
       " 'MEDICINE',\n",
       " 'ROAD TRANSPORT',\n",
       " 'NON-FERROUS METALS',\n",
       " 'GAS',\n",
       " 'INDUSTRIES',\n",
       " 'AUDIO',\n",
       " 'PNEUMATICS',\n",
       " 'MINING',\n",
       " 'TELECOMMUNICATIONS',\n",
       " 'SHIPPING',\n",
       " 'RAIL TRANSPORT',\n",
       " 'COMPUTING',\n",
       " 'PHYSICS',\n",
       " 'SPORT',\n",
       " 'MECHANICAL ENGINEERING',\n",
       " 'CHEMISTRY',\n",
       " 'HEAT ENGINES',\n",
       " 'AERONAUTICS',\n",
       " 'EXPLOSIVES',\n",
       " 'DOMESTIC EQUIPMENT',\n",
       " 'ELECTRICAL AND ELECTRONIC ENGINEERING',\n",
       " 'FERROUS METALS',\n",
       " 'CARTOGRAPHY',\n",
       " 'CIVIL AND MECHANICAL ENGINEERING',\n",
       " 'BT C',\n",
       " 'HYDRAULICS',\n",
       " 'OTHER']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = [re.search(r'[A-Z\\-\\s]+',str(t)) for t in collection.df.taxonomy.unique()]\n",
    "matches = set([m.group().strip() for m in matches if m])\n",
    "candidate_labels = list({i for i in matches if len(i) > 1})\n",
    "candidate_labels.append('OTHER')\n",
    "candidate_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d6c08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(images=image, text=candidate_labels, return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3647bca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760c9844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "logits = outputs.logits_per_image[0]\n",
    "probs = logits.softmax(dim=-1).numpy()\n",
    "scores = probs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836604ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [\n",
    "    {\"score\": score, \"label\": candidate_label}\n",
    "        for score, candidate_label in sorted(zip(probs, candidate_labels), key=lambda x: -x[0])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a51b2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e434243c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.Series(scores, index=candidate_labels).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c562077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits = outputs.logits_per_image[0]\n",
    "probs = logits.softmax(dim=-1).numpy()\n",
    "scores = probs.tolist()\n",
    "\n",
    "result = [\n",
    "    {\"score\": score, \"label\": candidate_label}\n",
    "        for score, candidate_label in sorted(zip(probs, candidate_labels), key=lambda x: -x[0])\n",
    "]\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d24b5c4",
   "metadata": {},
   "source": [
    "# Nomic Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5970131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nomic import atlas\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc5b581",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nomic login pyKINnSOXSivweuAXxprY7j8NtVFI88WC7AeE3BnLAmQZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07790dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nms_clip_embeddigns = np.array(nms.dataset['clip_image_embedding'])\n",
    "base_url = 'https://www.nms.ac.uk/search.axd?command=getcontent&server=Detail&value='\n",
    "nms.df['url'] = nms.df.img_loc.apply(lambda x: base_url + x)\n",
    "nms_data = [{'category': str(row.taxonomy), 'collection':'nms','id': str(i), 'url': row.url}\n",
    "            for i, row in nms.df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779d8ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "smg_clip_embeddigns = np.array(smg.dataset['clip_image_embedding'])\n",
    "base_url = 'https://coimages.sciencemuseumgroup.org.uk/images/'\n",
    "smg.df['url'] = smg.df.img_loc.apply(lambda x: base_url + x)\n",
    "smg_data = [{'category': str(row.taxonomy), 'collection':'smg','id': str(i), 'url': row.url}\n",
    "            for i, row in smg.df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6293c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.concatenate([nms_clip_embeddigns,smg_clip_embeddigns], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c0f759",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = nms_data + smg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d549a66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data), len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0ec047",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = atlas.map_embeddings(embeddings=embeddings,\n",
    "                                data=data,\n",
    "                                id_field='id',\n",
    "                                name='CE Map',\n",
    "                                colorable_fields=['category','collection'],\n",
    "                                reset_project_if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e04af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nms.df['tax_simpl'] = nms.df.taxonomy.apply(lambda x: re.search(r'[A-Z\\-\\s]+', str(x)))\n",
    "nms.df['tax_simpl'] = nms.df['tax_simpl'].apply(lambda x: x.group() if x else 'OTHER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392c5ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_embeddigns.shape, len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c649c2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d728c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(nms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b151ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nms.load_clip_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c5341b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2747439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "captioner = pipeline(\"image-to-text\",model=\"google/pix2struct-textcaps-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ecabe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idx = 302\n",
    "captioner(nms.df.iloc[idx].img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ab221b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(nms.df.iloc[idx].img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b6c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "df = nms.df.copy()\n",
    "\n",
    "# Define a function to load images from file paths\n",
    "def load_image(image_path):\n",
    "    return Image.open(image_path)\n",
    "\n",
    "# Apply the image loading function to the DataFrame\n",
    "df[\"image\"] = df[\"img_path\"]#.apply(load_image)\n",
    "df.rename({'description':'text'}, axis=1, inplace=True)\n",
    "# Create a Hugging Face dataset\n",
    "dataset = Dataset.from_pandas(df[['text','image']])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5543dcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcaf15e",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a988cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids2ints = {}\n",
    "\n",
    "for i,r_id in enumerate(list(nms.df.record_id)):\n",
    "    ids2ints[r_id] = i\n",
    "    \n",
    "for i,r_id in enumerate(list(smg.df.record_id)):\n",
    "    ids2ints[r_id] = nms.df.shape[0] + i   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f83281b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = list(ids2ints.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761f55e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_to_edgelist(results,e1):\n",
    "    df = pd.DataFrame({k: v[0] for k,v in results.items() if k !='embeddings'} )\n",
    "    df = pd.concat([df,df.metadatas.apply(pd.Series)], axis=1)\n",
    "    df['distances'] = (1 / (1+ df.distances)) * 100\n",
    "    return [(e1,\n",
    "            ids2ints[row.record_id], \n",
    "            row.distances\n",
    "                        ) for i, row in df.iterrows() \n",
    "                if e1 != ids2ints[row.record_id]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e645f632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "nodes = []\n",
    "names = []\n",
    "edges = []\n",
    "\n",
    "for i in tqdm(range(1000)): #len(nms.dataset)\n",
    "    \n",
    "    \n",
    "    results_smg = collection.query(\n",
    "            query_embeddings=[list(np.array(nms.dataset[i]['clip_image_embedding']).astype(float))],\n",
    "            n_results=3,\n",
    "            where={\"collection\": \"smg\"},\n",
    "                )\n",
    "    e1 = ids2ints[nms.dataset[i]['record_id']]\n",
    "    \n",
    "    edges.extend(result_to_edgelist(results_smg,e1))\n",
    "    \n",
    "    \n",
    "    results_nms = collection.query(\n",
    "            query_embeddings=[list(np.array(nms.dataset[i]['clip_image_embedding']).astype(float))],\n",
    "            n_results=3,\n",
    "            where={\"collection\": \"nms\"},\n",
    "                )\n",
    "    \n",
    "    edges.extend(result_to_edgelist(results_nms,e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b15966",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = []\n",
    "for i in edges:\n",
    "    nodes.extend(i[:2])\n",
    "nodes = list(set(nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9627f438",
   "metadata": {},
   "outputs": [],
   "source": [
    "ints2ids = {v : k for k,v in ids2ints.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16630c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [str(ints2ids[n]) for n in nodes] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c79325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "#net = Network(notebook=True)\n",
    "net = Network(height=\"750px\", \n",
    "              width=\"100%\", \n",
    "              bgcolor=\"#222222\", \n",
    "              font_color=\"white\", \n",
    "              cdn_resources='remote', \n",
    "              #filter_menu=True, \n",
    "              notebook=True)\n",
    "\n",
    "net.add_nodes(\n",
    "    nodes,\n",
    "    label=label,\n",
    "    color=[\"#00bfff\" if i < nms.df.shape[0] else \"#ffc0cb\" for i in nodes],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fae6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.add_edges(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0661ae1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#net.show(\"network.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5760eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#net.show_buttons(filter_=['physics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07229d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = draw_network(\n",
    "    nodes, df, minium_weight=0, repulsion=100, spring_length=500, buttons=[\"physics\"]\n",
    ")\n",
    "net.show(\"match_with_buttons.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8ae04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.show_buttons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7d6b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e537daf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in /Users/kasparbeelen/anaconda3/envs/ce/lib/python3.9/site-packages (0.41.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/kasparbeelen/anaconda3/envs/ce/lib/python3.9/site-packages (0.1.99)\n",
      "Requirement already satisfied: accelerate in /Users/kasparbeelen/anaconda3/envs/ce/lib/python3.9/site-packages (0.22.0)\n",
      "Requirement already satisfied: transformers in /Users/kasparbeelen/anaconda3/envs/ce/lib/python3.9/site-packages (4.33.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/kasparbeelen/anaconda3/envs/ce/lib/python3.9/site-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kasparbeelen/anaconda3/envs/ce/lib/python3.9/site-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/kasparbeelen/anaconda3/envs/ce/lib/python3.9/site-packages (from accelerate) (2.1.0)\n",
      "Requirement already satisfied: pyyaml in /Users/kasparbeelen/anaconda3/envs/ce/lib/python3.9/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: psutil in /Users/kasparbeelen/anaconda3/envs/ce/lib/python3.9/site-packages (from accelerate) (5.8.0)\n",
      "Requirement already satisfied: filelock in /Users/kasparbeelen/anaconda3/envs/ce/lib/python3.9/site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/kasparbeelen/anaconda3/envs/ce/lib/python3.9/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: requests in /Users/kasparbeelen/anaconda3/envs/ce/lib/python3.9/site-packages (from transformers) (2.28.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /Users/kasparbeelen/anaconda3/envs/ce/lib/python3.9/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/kasparbeelen/anaconda3/envs/ce/lib/python3.9/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/kasparbeelen/anaconda3/envs/ce/lib/python3.9/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/kasparbeelen/anaconda3/envs/ce/lib/python3.9/site-packages (from transformers) (2023.5.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/kasparbeelen/anaconda3/envs/ce/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: fsspec in /Users/kasparbeelen/anaconda3/envs/ce/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.5.0)\n",
      "Requirement already satisfied: sympy in /Users/kasparbeelen/anaconda3/envs/ce/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: jinja2 in /Users/kasparbeelen/anaconda3/envs/ce/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: networkx in /Users/kasparbeelen/anaconda3/envs/ce/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/kasparbeelen/anaconda3/envs/ce/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/kasparbeelen/anaconda3/envs/ce/lib/python3.9/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kasparbeelen/anaconda3/envs/ce/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kasparbeelen/anaconda3/envs/ce/lib/python3.9/site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kasparbeelen/anaconda3/envs/ce/lib/python3.9/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/kasparbeelen/anaconda3/envs/ce/lib/python3.9/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes sentencepiece accelerate transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8d5b6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"HuggingFaceM4/idefics-9b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d63e93b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using `load_in_8bit=True` requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes `pip install -i https://test.pypi.org/simple/ bitsandbytes` or pip install bitsandbytes` ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m quantization_config \u001b[38;5;241m=\u001b[39m BitsAndBytesConfig(\n\u001b[1;32m      5\u001b[0m     load_in_4bit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m     bnb_4bit_compute_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m processor \u001b[38;5;241m=\u001b[39m AutoProcessor\u001b[38;5;241m.\u001b[39mfrom_pretrained(checkpoint)\n\u001b[0;32m---> 11\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mIdeficsForVisionText2Text\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantization_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ce/lib/python3.9/site-packages/transformers/modeling_utils.py:2487\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_in_8bit \u001b[38;5;129;01mor\u001b[39;00m load_in_4bit:\n\u001b[1;32m   2486\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_accelerate_available() \u001b[38;5;129;01mand\u001b[39;00m is_bitsandbytes_available()):\n\u001b[0;32m-> 2487\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m   2488\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `load_in_8bit=True` requires Accelerate: `pip install accelerate` and the latest version of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2489\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m bitsandbytes `pip install -i https://test.pypi.org/simple/ bitsandbytes` or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2490\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m pip install bitsandbytes` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2491\u001b[0m         )\n\u001b[1;32m   2493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2494\u001b[0m         \u001b[38;5;66;03m# We force the `dtype` to be float16, this is a requirement from `bitsandbytes`\u001b[39;00m\n\u001b[1;32m   2495\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   2496\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverriding torch_dtype=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with `torch_dtype=torch.float16` due to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2497\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2498\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2499\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m torch_dtype=torch.float16 to remove this warning.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2500\u001b[0m         )\n",
      "\u001b[0;31mImportError\u001b[0m: Using `load_in_8bit=True` requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes `pip install -i https://test.pypi.org/simple/ bitsandbytes` or pip install bitsandbytes` "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import IdeficsForVisionText2Text, AutoProcessor, BitsAndBytesConfig\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(checkpoint)\n",
    "\n",
    "model = IdeficsForVisionText2Text.from_pretrained(\n",
    "    checkpoint,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "642b9a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://test.pypi.org/simple/\r\n",
      "Requirement already satisfied: bitsandbytes in /Users/kasparbeelen/anaconda3/envs/ce/lib/python3.9/site-packages (0.41.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -i https://test.pypi.org/simple/ bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c836c21c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ner-al",
   "language": "python",
   "name": "ner-al"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
