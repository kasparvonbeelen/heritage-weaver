{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1062ad1f",
   "metadata": {},
   "source": [
    "# Ingest and process data\n",
    "\n",
    "This notebook loads the data that was stored on Box, and converts it to dataframe and dataset with a common format across all collections.\n",
    "\n",
    "It provides functionality for downlaoding images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0846e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4390a967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.weaving_tools import NMSCollection, SMGCollection, BTCollection\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5bdcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nms = NMSCollection(device='mps',img_folder='nms_imgs')\n",
    "nms.load_original_csvs(files=list(Path('data').glob('NMS_*.*')))\n",
    "nms.save_csv('data/NMS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123d6039",
   "metadata": {},
   "outputs": [],
   "source": [
    "smg = SMGCollection(device='mps', img_folder='smg_imgs')\n",
    "smg.load_from_json('data/smg_objects_06_06_2022.json')\n",
    "smg.save_csv('data/SMG.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47850e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = BTCollection(device='mps', img_folder='bt_imgs')\n",
    "bt.load_from_xml('data/bt_catalogue.xml')\n",
    "bt.save_csv('data/BT.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8583207e",
   "metadata": {},
   "source": [
    "# Download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6662cac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = SMGCollection(img_folder=Path('smg_imgs'))\n",
    "collection.load_from_csv('data/SMG.csv')\n",
    "collection.fetch_images(n=5)\n",
    "#collection.save_csv('data/SMG.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce570b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = BTCollection(img_folder=Path('bt_imgs'))\n",
    "collection.load_from_csv('data/BT.csv')\n",
    "collection.fetch_images(n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7dee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = NMSCollection(img_folder=Path('nms_imgs'))\n",
    "collection.load_from_csv('data/NMS.csv')\n",
    "collection.fetch_images(n=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0799d64",
   "metadata": {},
   "source": [
    "# Create vector database\n",
    "\n",
    "## Vectorize image and text in each collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18683950",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_ckpt = 'clip-ViT-B-32'#'openai/clip-vit-base-patch32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551e1bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "nms = NMSCollection(device='mps',img_folder='nms_imgs')\n",
    "nms.load_from_csv('data/NMS.csv')\n",
    "nms.vectorize_collection(clip_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b9557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "smg = SMGCollection(device='mps',img_folder='smg_imgs')\n",
    "smg.load_from_csv('data/SMG.csv')\n",
    "# temp to for testing purposes remove later\n",
    "smg.df = smg.df.sample(frac=0.05).reset_index()\n",
    "smg.vectorize_collection(clip_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad6eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = BTCollection(device='mps', img_folder='bt_imgs')\n",
    "bt.load_from_csv('data/BT.csv')\n",
    "bt.vectorize_collection(clip_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fe3566",
   "metadata": {},
   "source": [
    "# Create Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0dd745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c326d742",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=\"ce_vector_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc64c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     client.delete_collection(name=\"congruence_engine\")\n",
    "# except Exception as e:\n",
    "#     print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b993c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.get_or_create_collection(name=\"congruence_engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d73e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "for coll in [nms,bt,smg]:\n",
    "    for mod in ['image']:\n",
    "        coll.add_embeddings_to_database(collection,mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee2a959",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06984dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for coll in [nms,bt,smg]:\n",
    "#     for mod in ['text']:\n",
    "#         coll.add_embeddings_to_database(collection,mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6468f338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8413d217",
   "metadata": {},
   "source": [
    "## Fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4136ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46903889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf0a4a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c98143f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5156c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f602894d",
   "metadata": {},
   "source": [
    "## Query and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fb0789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tools.weaving_tools import plot_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c27a753",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = nms.clip_model.encode('machines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c55916",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3000\n",
    "query_embedding = np.array(nms.dataset[idx]['clip_image_embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d53564",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.query(\n",
    "    query_embeddings=[list(query_embedding.astype(float))],\n",
    "    n_results=10,\n",
    "    where={\"collection\": \"nms\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dceacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df = pd.DataFrame(results['metadatas'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7c9181",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(nms.dataset[idx]['img_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc73b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(query_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e914c6",
   "metadata": {},
   "source": [
    "# Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157fac73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#idx = 10\n",
    "query = 'instrument'\n",
    "#query = 'engine'\n",
    "query_df = nms.query_collection(query, field='clip_embedding', index_type='clip', k=25)\n",
    "print(query)\n",
    "nms.plot_images(query_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a58ed81",
   "metadata": {},
   "source": [
    "# Zero Shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21687e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c5b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U transformers\n",
    "# old version '4.25.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca518e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForZeroShotImageClassification\n",
    "checkpoint = 'openai/clip-vit-base-patch32'\n",
    "model = AutoModelForZeroShotImageClassification.from_pretrained(checkpoint)\n",
    "processor = AutoProcessor.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e00c828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a7080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3000#10\n",
    "image = Image.open(nms.df.iloc[idx].img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e016ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb99444",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nms.df.iloc[idx].taxonomy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e752b566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#pattern = re.compile()\n",
    "matches = [re.search(r'[A-Z\\-\\s]+',str(t)) for t in nms.df.taxonomy.unique()]\n",
    "matches = set([m.group().strip() for m in matches if m])\n",
    "candidate_labels = list({i for i in matches if len(i) > 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d6c08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(images=image, text=candidate_labels, return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3647bca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760c9844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "logits = outputs.logits_per_image[0]\n",
    "probs = logits.softmax(dim=-1).numpy()\n",
    "scores = probs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836604ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [\n",
    "    {\"score\": score, \"label\": candidate_label}\n",
    "        for score, candidate_label in sorted(zip(probs, candidate_labels), key=lambda x: -x[0])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a51b2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e434243c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.Series(scores, index=candidate_labels).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c562077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits = outputs.logits_per_image[0]\n",
    "probs = logits.softmax(dim=-1).numpy()\n",
    "scores = probs.tolist()\n",
    "\n",
    "result = [\n",
    "    {\"score\": score, \"label\": candidate_label}\n",
    "        for score, candidate_label in sorted(zip(probs, candidate_labels), key=lambda x: -x[0])\n",
    "]\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d24b5c4",
   "metadata": {},
   "source": [
    "# Nomic Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5970131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nomic import atlas\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc5b581",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nomic login pyKINnSOXSivweuAXxprY7j8NtVFI88WC7AeE3BnLAmQZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07790dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nms_clip_embeddigns = np.array(nms.dataset['clip_image_embedding'])\n",
    "base_url = 'https://www.nms.ac.uk/search.axd?command=getcontent&server=Detail&value='\n",
    "nms.df['url'] = nms.df.img_loc.apply(lambda x: base_url + x)\n",
    "nms_data = [{'category': str(row.taxonomy), 'collection':'nms','id': str(i), 'url': row.url}\n",
    "            for i, row in nms.df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779d8ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "smg_clip_embeddigns = np.array(smg.dataset['clip_image_embedding'])\n",
    "base_url = 'https://coimages.sciencemuseumgroup.org.uk/images/'\n",
    "smg.df['url'] = smg.df.img_loc.apply(lambda x: base_url + x)\n",
    "smg_data = [{'category': str(row.taxonomy), 'collection':'smg','id': str(i), 'url': row.url}\n",
    "            for i, row in smg.df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6293c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.concatenate([nms_clip_embeddigns,smg_clip_embeddigns], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c0f759",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = nms_data + smg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d549a66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data), len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0ec047",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = atlas.map_embeddings(embeddings=embeddings,\n",
    "                                data=data,\n",
    "                                id_field='id',\n",
    "                                name='CE Map',\n",
    "                                colorable_fields=['category','collection'],\n",
    "                                reset_project_if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e04af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nms.df['tax_simpl'] = nms.df.taxonomy.apply(lambda x: re.search(r'[A-Z\\-\\s]+', str(x)))\n",
    "nms.df['tax_simpl'] = nms.df['tax_simpl'].apply(lambda x: x.group() if x else 'OTHER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392c5ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_embeddigns.shape, len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c649c2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d728c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(nms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b151ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nms.load_clip_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c5341b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2747439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "captioner = pipeline(\"image-to-text\",model=\"google/pix2struct-textcaps-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ecabe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idx = 302\n",
    "captioner(nms.df.iloc[idx].img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ab221b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(nms.df.iloc[idx].img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b6c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "df = nms.df.copy()\n",
    "\n",
    "# Define a function to load images from file paths\n",
    "def load_image(image_path):\n",
    "    return Image.open(image_path)\n",
    "\n",
    "# Apply the image loading function to the DataFrame\n",
    "df[\"image\"] = df[\"img_path\"]#.apply(load_image)\n",
    "df.rename({'description':'text'}, axis=1, inplace=True)\n",
    "# Create a Hugging Face dataset\n",
    "dataset = Dataset.from_pandas(df[['text','image']])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5543dcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcaf15e",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a988cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids2ints = {}\n",
    "\n",
    "for i,r_id in enumerate(list(nms.df.record_id)):\n",
    "    ids2ints[r_id] = i\n",
    "    \n",
    "for i,r_id in enumerate(list(smg.df.record_id)):\n",
    "    ids2ints[r_id] = nms.df.shape[0] + i   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f83281b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = list(ids2ints.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761f55e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_to_edgelist(results,e1):\n",
    "    df = pd.DataFrame({k: v[0] for k,v in results.items() if k !='embeddings'} )\n",
    "    df = pd.concat([df,df.metadatas.apply(pd.Series)], axis=1)\n",
    "    df['distances'] = (1 / (1+ df.distances)) * 100\n",
    "    return [(e1,\n",
    "            ids2ints[row.record_id], \n",
    "            row.distances\n",
    "                        ) for i, row in df.iterrows() \n",
    "                if e1 != ids2ints[row.record_id]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e645f632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "nodes = []\n",
    "names = []\n",
    "edges = []\n",
    "\n",
    "for i in tqdm(range(1000)): #len(nms.dataset)\n",
    "    \n",
    "    \n",
    "    results_smg = collection.query(\n",
    "            query_embeddings=[list(np.array(nms.dataset[i]['clip_image_embedding']).astype(float))],\n",
    "            n_results=3,\n",
    "            where={\"collection\": \"smg\"},\n",
    "                )\n",
    "    e1 = ids2ints[nms.dataset[i]['record_id']]\n",
    "    \n",
    "    edges.extend(result_to_edgelist(results_smg,e1))\n",
    "    \n",
    "    \n",
    "    results_nms = collection.query(\n",
    "            query_embeddings=[list(np.array(nms.dataset[i]['clip_image_embedding']).astype(float))],\n",
    "            n_results=3,\n",
    "            where={\"collection\": \"nms\"},\n",
    "                )\n",
    "    \n",
    "    edges.extend(result_to_edgelist(results_nms,e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b15966",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = []\n",
    "for i in edges:\n",
    "    nodes.extend(i[:2])\n",
    "nodes = list(set(nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9627f438",
   "metadata": {},
   "outputs": [],
   "source": [
    "ints2ids = {v : k for k,v in ids2ints.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16630c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [str(ints2ids[n]) for n in nodes] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c79325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "#net = Network(notebook=True)\n",
    "net = Network(height=\"750px\", \n",
    "              width=\"100%\", \n",
    "              bgcolor=\"#222222\", \n",
    "              font_color=\"white\", \n",
    "              cdn_resources='remote', \n",
    "              #filter_menu=True, \n",
    "              notebook=True)\n",
    "\n",
    "net.add_nodes(\n",
    "    nodes,\n",
    "    label=label,\n",
    "    color=[\"#00bfff\" if i < nms.df.shape[0] else \"#ffc0cb\" for i in nodes],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fae6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.add_edges(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0661ae1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#net.show(\"network.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5760eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#net.show_buttons(filter_=['physics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07229d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = draw_network(\n",
    "    nodes, df, minium_weight=0, repulsion=100, spring_length=500, buttons=[\"physics\"]\n",
    ")\n",
    "net.show(\"match_with_buttons.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8ae04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.show_buttons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7d6b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e537daf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bitsandbytes sentencepiece accelerate transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d5b6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"HuggingFaceM4/idefics-9b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63e93b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import IdeficsForVisionText2Text, AutoProcessor, BitsAndBytesConfig\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(checkpoint)\n",
    "\n",
    "model = IdeficsForVisionText2Text.from_pretrained(\n",
    "    checkpoint,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642b9a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -i https://test.pypi.org/simple/ bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c836c21c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ner-al",
   "language": "python",
   "name": "ner-al"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
